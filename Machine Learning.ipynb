{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use machine learning to refer to creating and using models that are learned from \n",
    "# data. This might be called predictive modeling or data mining. Typically, our goal will\n",
    "# be to use existing data to develop models that we can use to predict various outcomes.\n",
    "# - Predicting whether an email message is spam or not\n",
    "# - Predicting whether a credit card transaction is fraudlent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERFITTING : producing a model that performs well on the data you train it on but \n",
    "#               that generalizes poorly to any new data. \n",
    "\n",
    "# UNDERFITTING : producing a model that does not perform well even on the training data, \n",
    "\n",
    "# Clearly, models that are too complex lead to overfitting and dont generalize well\n",
    "# beyond the data they were trainded on.\n",
    "\n",
    "# The most fundamental approach involves using different data to train the model and \n",
    "# to test the model\n",
    "\n",
    "# The simplest way to do this is to split your data set, so that 2/3 of it is used to\n",
    "# train the model, after which we measure the model 's performance on the remaining 1/3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,prob):\n",
    "    # split data into fractions [prob, 1 - prob]\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random <prob else 1].append(row)\n",
    "    return resullts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-d46ffe141149>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d46ffe141149>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    data zip(x,y)                                 # pair corresponding values\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Often we will have a matrix x of input vars and a vector y of output\n",
    "# var. In that case, we need to make sure to put corresponding values together in \n",
    "# either the training data or the test data.\n",
    "\n",
    "def train_test_split(x,y,test_pct):\n",
    "    data zip(x,y)                                 # pair corresponding values\n",
    "    train,test = split_data(data, 1 - test_pct)   # split the data set of pairs\n",
    "    x_train, y_train = zip (*train)               # magical up-zip trick\n",
    "    x_test, y_test = zip(*test)\n",
    "    return x_train, x_test , y_train , y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model was overfit to the training data, then it will hopefully\n",
    "# perform poorly on the completely seperated test data. Said differently,\n",
    "# if it performs well on the test data, then you can be more confident\n",
    "# that it 's fitting rather than over fitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a set of labeled data and such a predictive model, every data point\n",
    "# lies in one of four categories.\n",
    "\n",
    "# True positive : \"This message is spam, and we correctly predicted spam\"\n",
    "# False positive (Type 1 error) : \"This message is not spam\" , but we predicted spam\"\n",
    "# False negative (Type 2 eorr) : this is a spam, but we predicted not a spam\n",
    "# True negative : this is not spam , and we predicted not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s see how my leukemia test fits into this framework. These days approximately 5\n",
    "# babies out of 1,000 are named Luke. And the lifetime prevalence of leukemia is about\n",
    "# 1.4%, or 14 out of every 1,000 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then use these to compute various statistics about model performance. \n",
    "# For example, accuracy is defined as the fraction of correct predictions.\n",
    "\n",
    "def accuracy(tp,fp,fn,tn):\n",
    "    correct = tp + tn\n",
    "    total = float ( tp + fp + fn + tn)\n",
    "    return float (correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98114\n"
     ]
    }
   ],
   "source": [
    "print accuracy(70,4930,13930,981070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014\n"
     ]
    }
   ],
   "source": [
    "# Precision measures how accurate our positive predictions were :\n",
    "def precision(tp,fp,fn,tn):\n",
    "    return tp / float(tp +fp)\n",
    "print precision(70,4930,13930,981070)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n"
     ]
    }
   ],
   "source": [
    "# recall measures what fraction of the positives our model idenfied\n",
    "def recall(tp,fp,fn,tn):\n",
    "    return tp/float(tp + fn)\n",
    "\n",
    "print recall(70,4930,13930,981070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall and precision are both bad, reflecting that this is not a good model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
